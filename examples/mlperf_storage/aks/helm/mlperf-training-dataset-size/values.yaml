# Default values for mlperf-training-dataset-size
image:
  repository: ghcr.io/azure/ai-infrastructure-on-azure/mlperf-storage
  tag: latest
  pullPolicy: Always

# Kueue integration (optional)
# Set queueName to enable Kueue workload management
kueue:
  queueName: "" # e.g., "gpu-local-queue" to use Kueue

job:
  restartPolicy: Never
  backoffLimit: 0

container:
  resources:
    requests:
      cpu: "1"
      memory: "4Gi"
    limits:
      cpu: "1"
      memory: "4Gi"

benchmark:
  # Model to emulate: cosmoflow, resnet50, unet3d
  model: unet3d
  # Client host memory in GB
  clientHostMemoryGiB: 128
  # Maximum number of accelerators
  maxAccelerators: 16
  # Number of client hosts
  numClientHosts: 2
  # Accelerator type (e.g., a100, h100)
  acceleratorType: a100
  # Additional parameters (space-separated key=value pairs)
  # Example: "buffer_size=64M thread_count=8"
  additionalParams: ""
  # Enable debug mode
  debug: false
  # Enable verbose mode
  verbose: false

storage:
  # REQUIRED: Name of the PersistentVolumeClaim to use for storage
  pvcName:
  mountPath: "/mnt/storage"
  resultsDir: "mlps-results"

nodeSelector: {}
tolerations: []
affinity: {}
