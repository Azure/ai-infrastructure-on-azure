#!/bin/bash
#SBATCH --gpus-per-node=8
#SBATCH --exclusive
#SBATCH -o download_data_%j.log

usage() {
    echo "Usage: $0 <container_image> <data_directory> [num_workers]"
    echo "  <container_image>: Path to the container image to use."
    echo "  <data_directory>: Path to the directory where data will be stored."
    echo "  [num_workers]: Optional. Number of workers to use (default: 16)."
    exit 1
}

# Validate arguments
if [ -z "$1" ] || [ -z "$2" ]; then
    echo "Error: Missing required arguments."
    usage
fi
CONT=$1
DATADIR=$2
NUM_WORKERS=${3:-16}

srun -l \
    --cpu-bind no \
    --container-image "${CONT}" \
    --container-mounts "${DATADIR}:/data" \
    --gpus-per-node=8 \
    --mem=0 \
        python /llm-foundry/scripts/data_prep/convert_dataset_hf.py \
            --dataset allenai/c4 \
            --data_subset en \
            --out_root /data/my-copy-c4 \
            --splits train val \
            --concat_tokens 2048 \
            --tokenizer EleutherAI/gpt-neox-20b \
            --eos_text '<|endoftext|>' \
            --num_workers $NUM_WORKERS
