# Default values for dataset-download
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# Dataset configuration
dataset:
  name: "allenai/c4"
  subset: "en"
  splits: ["train", "val"]
  concatTokens: 2048
  tokenizer: "EleutherAI/gpt-neox-20b"
  eosText: "<|endoftext|>"

# Container image configuration
image:
  repository: ghcr.io/azure/ai-infrastructure-on-azure/llm-foundry
  tag: v0.18.0
  pullPolicy: IfNotPresent

# Storage configuration
storage:
  # Path where the converted dataset will be stored
  dataPath: "/data/my-copy-c4"
  # Name of the existing PVC to use for shared storage
  # This should be created by the shared-storage helm chart
  pvcName: "shared-blob-storage"

# Resource configuration
resources:
  # Number of worker processes for dataset conversion
  workers: 8
  # CPU per worker (will be multiplied by workers in template)
  cpuPerWorker: 2
  memoryPerWorkerGi: 4
  # shared memory size for the job
  shmSize: "8Gi"

# Job configuration
job:
  # Restart policy for the job
  restartPolicy: Never
  # Backoff limit for failed pods
  backoffLimit: 3
  # Time to live after job completion (in seconds)
  ttlSecondsAfterFinished: 3600

# Node selector for job placement
nodeSelector: {}

# Tolerations for node taints
tolerations: []

# Affinity rules
affinity: {}
