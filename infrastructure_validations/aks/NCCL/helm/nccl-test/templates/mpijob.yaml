apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: {{ include "nccl-test.fullname" . }}
spec:
  slotsPerWorker: {{ .Values.gpusPerNode }}
  runPolicy:
    cleanPodPolicy: Running
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        metadata:
          labels:
            app: nccl-test
        spec:
          restartPolicy: OnFailure
          containers:
          - image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
            name: nccl
            imagePullPolicy: {{ .Values.image.pullPolicy }}
            env:
            {{- range $key, $value := .Values.ncclTest.env }}
            - name: {{ $key }}
              value: "{{ $value }}"
            {{- end }}
            command:
            - /bin/bash
            - -c
            args:
            - |
              set -xe
              NUM_NODES={{ .Values.nodes }}
              DEVICES_PER_NODE={{ .Values.gpusPerNode }}
              NP=$(($NUM_NODES * $DEVICES_PER_NODE))
              until mpirun -np ${NP} -hostfile /etc/mpi/hostfile -x LD_LIBRARY_PATH -bind-to none hostname 2>/dev/null; do sleep 5; done
              mpirun \
                --allow-run-as-root \
                -np $NP \
                --map-by ppr:$DEVICES_PER_NODE:node:pe=12 \
                --bind-to core \
                --report-bindings \
                -hostfile /etc/mpi/hostfile \
                -mca plm_rsh_no_tree_spawn 1 \
                -mca plm_rsh_num_concurrent 800 \
                -mca coll_hcoll_enable 0 \
                -x LD_LIBRARY_PATH \
                {{- range $key, $value := .Values.ncclTest.env }}
                -x {{ $key }} \
                {{- end }}
                all_reduce_perf_mpi {{ .Values.ncclTest.testArgs }}
            resources:
              requests:
                cpu: 50m
                memory: 128Mi
          enableServiceLinks: false
          automountServiceAccountToken: false
    Worker:
      replicas: {{ .Values.nodes }}
      template:
        metadata:
          labels:
            # IMPORTANT: This label is used by the affinity rules below
            task: {{ include "nccl-test.fullname" . }}
        spec:
          {{- if or .Values.affinity.required .Values.affinity.preferred }}
          affinity:
            podAffinity:
              {{- if .Values.affinity.required }}
              requiredDuringSchedulingIgnoredDuringExecution:
              {{- range .Values.affinity.required }}
                - labelSelector:
                    matchLabels:
                      task: {{ include "nccl-test.fullname" $ }}
                  topologyKey: {{ .topologyKey }}
              {{- end }}
              {{- end }}
              {{- if .Values.affinity.preferred }}
              preferredDuringSchedulingIgnoredDuringExecution:
              {{- range .Values.affinity.preferred }}
                - weight: {{ .weight | default 100 }}
                  podAffinityTerm:
                    labelSelector:
                      matchLabels:
                        task: {{ include "nccl-test.fullname" $ }}
                    topologyKey: {{ .topologyKey }}
              {{- end }}
              {{- end }}
          {{- end }}
          containers:
          - image: {{ .Values.image.repository }}:{{ .Values.image.tag }}
            name: nccl
            imagePullPolicy: {{ .Values.image.pullPolicy }}
            resources:
              requests:
                {{ .Values.gpuResource }}: {{ .Values.gpusPerNode }}
                {{ .Values.rdmaResource }}: {{ .Values.gpusPerNode }}
              limits:
                {{ .Values.gpuResource }}: {{ .Values.gpusPerNode }}
                {{ .Values.rdmaResource }}: {{ .Values.gpusPerNode }}
            securityContext:
              capabilities:
                add: ["IPC_LOCK"]
            volumeMounts:
            - name: shm
              mountPath: /dev/shm
          volumes:
          - name: shm
            emptyDir:
              medium: Memory
          enableServiceLinks: false
          automountServiceAccountToken: false