name: Deploy Azure CycleCloud Workspace for Slurm (Reusable)

on:
  workflow_call:
    inputs:
      location:
        description: "Azure region (e.g., westus3, westeurope, westus2)"
        required: false
        type: string
        default: "westus3"
      htc_sku:
        description: "HTC partition VM SKU (e.g., Standard_F2s_v2)"
        required: false
        type: string
        default: "Standard_D4as_v5"
      hpc_sku:
        description: "HPC partition VM SKU (e.g., Standard_HB176rs_v4)"
        required: false
        type: string
        default: "Standard_D4as_v5"
      gpu_sku:
        description: "GPU partition VM SKU (e.g., Standard_ND96amsr_A100_v4)"
        required: false
        type: string
        default: "Standard_D4as_v5"
      scheduler_sku:
        description: "Scheduler node VM SKU"
        required: false
        default: "Standard_D4as_v5"
        type: string
      login_sku:
        description: "Login node VM SKU"
        required: false
        default: "Standard_D4as_v5"
        type: string
      cluster_name:
        description: "Slurm cluster name"
        required: false
        default: "ccw"
        type: string
      workspace_ref:
        description: "Git ref (branch/tag) to checkout"
        required: false
        default: "2025.12.01"
        type: string
      htc_max_nodes:
        description: "Maximum nodes for HTC partition"
        required: false
        default: "100"
        type: string
      hpc_max_nodes:
        description: "Maximum nodes for HPC partition"
        required: false
        default: "16"
        type: string
      gpu_max_nodes:
        description: "Maximum nodes for GPU partition"
        required: false
        default: "8"
        type: string
      data_filesystem:
        description: "Enable Azure Managed Lustre data filesystem"
        required: false
        default: false
        type: boolean
      deploy_immediately:
        description: "Deploy immediately after generating parameters"
        required: false
        default: false
        type: boolean
      with_openondemand:
        description: "Enable Open OnDemand web portal"
        required: false
        default: false
        type: boolean
      image:
        description: "VM image to use for all nodes (optional)"
        required: false
        type: string

concurrency:
  group: deploy-ccws
  cancel-in-progress: false

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: testing

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Validate required secrets
        run: |
          set -euo pipefail
          if [ -z "${{ secrets.SSH_PUBLIC_KEY }}" ]; then
            echo "::error::SSH_PUBLIC_KEY secret is required"
            exit 1
          fi
          if [ -z "${{ secrets.ADMIN_PASSWORD }}" ]; then
            echo "::error::ADMIN_PASSWORD secret is required"
            exit 1
          fi

      - name: Generate resource group name
        id: rg_name
        run: |
          set -euo pipefail
          # Generate resource group name with pattern ccw_YYDDMMHHmm
          timestamp=$(date -u +"%y%d%m%H%M")
          rg_name="ccw_${timestamp}"
          echo "resource_group=${rg_name}" >> "$GITHUB_OUTPUT"
          echo "Generated resource group name: ${rg_name}"

      - name: Accept Azure Marketplace terms
        if: inputs.deploy_immediately
        run: |
          set -euo pipefail
          echo "Deployment enabled - accepting Azure CycleCloud marketplace terms..."
          az vm image terms accept --publisher azurecyclecloud --offer azure-cyclecloud --plan cyclecloud8-gen2 || {
            echo "Failed to accept marketplace terms, but continuing..."
          }

      - name: Create SSH public key file
        run: |
          set -euo pipefail
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PUBLIC_KEY }}" > ~/.ssh/id_rsa.pub
          chmod 644 ~/.ssh/id_rsa.pub

      - name: Set script permissions
        run: |
          set -euo pipefail
          chmod +x infrastructure_references/azure_cyclecloud_workspace_for_slurm/scripts/deploy-ccws.sh

      - name: Build deployment command
        id: build_command
        env:
          SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          RG_NAME: ${{ steps.rg_name.outputs.resource_group }}
          LOCATION: ${{ inputs.location }}
          ADMIN_PASSWORD: ${{ secrets.ADMIN_PASSWORD }}
          HTC_SKU: ${{ inputs.htc_sku }}
          HPC_SKU: ${{ inputs.hpc_sku }}
          GPU_SKU: ${{ inputs.gpu_sku }}
          SCHEDULER_SKU: ${{ inputs.scheduler_sku }}
          LOGIN_SKU: ${{ inputs.login_sku }}
          CLUSTER_NAME: ${{ inputs.cluster_name }}
          WORKSPACE_REF: ${{ inputs.workspace_ref }}
          HTC_MAX: ${{ inputs.htc_max_nodes }}
          HPC_MAX: ${{ inputs.hpc_max_nodes }}
          GPU_MAX: ${{ inputs.gpu_max_nodes }}
          DATA_FILESYSTEM: ${{ inputs.data_filesystem }}
          DEPLOY_IMMEDIATELY: ${{ inputs.deploy_immediately }}
          IMAGE: ${{ inputs.image }}
        run: |
          set -euo pipefail

          script="./infrastructure_references/azure_cyclecloud_workspace_for_slurm/scripts/deploy-ccws.sh"
          # Build command as an array to avoid quoting issues and eval
          cmd=(
            "$script"
            --subscription-id "$SUBSCRIPTION_ID"
            --resource-group "$RG_NAME"
            --location "$LOCATION"
            --ssh-public-key-file "$HOME/.ssh/id_rsa.pub"
            --admin-password "$ADMIN_PASSWORD"
            --htc-sku "$HTC_SKU"
            --hpc-sku "$HPC_SKU"
            --gpu-sku "$GPU_SKU"
            --admin-username "hpcadmin"
            --scheduler-sku "$SCHEDULER_SKU"
            --login-sku "$LOGIN_SKU"
            --cluster-name "$CLUSTER_NAME"
            --workspace-ref "$WORKSPACE_REF"
            --htc-max-nodes "$HTC_MAX"
            --hpc-max-nodes "$HPC_MAX"
            --gpu-max-nodes "$GPU_MAX"
            --bastion --accept-marketplace --no-az --silent
          )

          if [ -n "${IMAGE}" ]; then
            cmd+=(--htc-image "$IMAGE")
            cmd+=(--hpc-image "$IMAGE")
            cmd+=(--gpu-image "$IMAGE")
            cmd+=(--scheduler-image "$IMAGE")
            cmd+=(--login-image "$IMAGE")
          fi

          if [ "${DATA_FILESYSTEM}" = "true" ]; then
            cmd+=(--data-filesystem)
          fi

          if [ "${DEPLOY_IMMEDIATELY}" = "true" ]; then
            cmd+=(--deploy)
          fi

          # Emit the command as a single line to outputs for visibility/logging
          printf 'command=%q ' "${cmd[@]}" >> "$GITHUB_OUTPUT"
          echo >> "$GITHUB_OUTPUT" # newline

      - name: Run deploy-ccws.sh script
        run: |
          set -euo pipefail
          cd "${{ github.workspace }}"
          echo "Executing deployment command..."
          # Rebuild command from outputs or just reconstruct directly (safer to run array again)
          script="./infrastructure_references/azure_cyclecloud_workspace_for_slurm/scripts/deploy-ccws.sh"
          args=(
            --subscription-id "${{ secrets.AZURE_SUBSCRIPTION_ID }}"
            --resource-group "${{ steps.rg_name.outputs.resource_group }}"
            --location "${{ inputs.location }}"
            --ssh-public-key-file "$HOME/.ssh/id_rsa.pub"
            --admin-password "${{ secrets.ADMIN_PASSWORD }}"
            --htc-sku "${{ inputs.htc_sku }}"
            --hpc-sku "${{ inputs.hpc_sku }}"
            --gpu-sku "${{ inputs.gpu_sku }}"
            --admin-username "hpcadmin"
            --scheduler-sku "${{ inputs.scheduler_sku }}"
            --login-sku "${{ inputs.login_sku }}"
            --workspace-ref "${{ inputs.workspace_ref }}"
            --htc-max-nodes "${{ inputs.htc_max_nodes }}"
            --hpc-max-nodes "${{ inputs.hpc_max_nodes }}"
            --gpu-max-nodes "${{ inputs.gpu_max_nodes }}"
            --bastion --accept-marketplace --no-az --silent
          )
          if [ -n "${{ inputs.image }}" ]; then
            args+=(--htc-image "${{ inputs.image }}")
            args+=(--hpc-image "${{ inputs.image }}")
            args+=(--gpu-image "${{ inputs.image }}")
            args+=(--scheduler-image "${{ inputs.image }}")
            args+=(--login-image "${{ inputs.image }}")
          fi
          if [ "${{ inputs.data_filesystem }}" = "true" ]; then
            args+=(--data-filesystem)
          fi
          if [ "${{ inputs.deploy_immediately }}" = "true" ]; then
            args+=(--deploy)
          fi
          # Do no start the Slurm cluster automatically
          args+=(--slurm-no-start)
          # Execute
          "$script" "${args[@]}"

      - name: Wait for CycleCloud VM cloud-init completion
        if: inputs.deploy_immediately
        timeout-minutes: 15
        run: |
          set -euo pipefail

          RG_NAME="${{ steps.rg_name.outputs.resource_group }}"
          VM_NAME="ccw-cyclecloud-vm"
          SEARCH_STRING="exiting after install"
          TIMEOUT_MINUTES=15
          CHECK_INTERVAL=30  # Check every 30 seconds
          MAX_ATTEMPTS=$((TIMEOUT_MINUTES * 60 / CHECK_INTERVAL))

          echo "üîç Waiting for cloud-init completion on '${VM_NAME}'..."
          echo "üîé Looking for: '${SEARCH_STRING}' in /var/log/cloud-init-output.log"
          echo "‚è±Ô∏è Timeout: ${TIMEOUT_MINUTES} minutes (${MAX_ATTEMPTS} attempts with ${CHECK_INTERVAL}s intervals)"

          INIT_COMPLETE=false

          for attempt in $(seq 1 "$MAX_ATTEMPTS"); do
            echo "üîÑ Attempt ${attempt}/${MAX_ATTEMPTS}: Checking cloud-init log..."
            
            # Run command on VM to check for the string
            RESULT=$(az vm run-command invoke \
              --resource-group "$RG_NAME" \
              --name "$VM_NAME" \
              --command-id RunShellScript \
              --scripts "grep -c '${SEARCH_STRING}' /var/log/cloud-init-output.log 2>/dev/null || echo 0" \
              --query "value[0].message" \
              --output tsv 2>/dev/null || echo "0")
            
            # Extract the count from the result (last line typically contains the output)
            COUNT=$(echo "$RESULT" | grep -oE '[0-9]+' | tail -1 || echo "0")
            
            if [ "$COUNT" -gt 0 ]; then
              echo "‚úÖ Found '${SEARCH_STRING}' in cloud-init log - installation complete!"
              INIT_COMPLETE=true
              break
            else
              echo "‚è≥ String not found yet, cloud-init still in progress..."
            fi
            
            if [ "$attempt" -lt "$MAX_ATTEMPTS" ]; then
              echo "üí§ Waiting ${CHECK_INTERVAL} seconds before next check..."
              sleep "$CHECK_INTERVAL"
            fi
          done

          if [ "$INIT_COMPLETE" = false ]; then
            echo "‚ùå FAILURE: Cloud-init did not complete within ${TIMEOUT_MINUTES} minutes"
            echo "::error::CycleCloud cloud-init did not complete - '${SEARCH_STRING}' not found in log"
            
            # Show last 50 lines of cloud-init log for debugging
            echo "üìã Last 50 lines of cloud-init log:"
            az vm run-command invoke \
              --resource-group "$RG_NAME" \
              --name "$VM_NAME" \
              --command-id RunShellScript \
              --scripts "tail -n 50 /var/log/cloud-init-output.log" \
              --query "value[0].message" \
              --output tsv || echo "Failed to retrieve log"
            exit 1
          else
            echo "üéâ SUCCESS: CycleCloud VM cloud-init completed successfully"
            echo "::notice::CycleCloud cloud-init completed - found '${SEARCH_STRING}'"
          fi

      - name: Inject EventGrid topic for CycleCloud Application.Setting
        id: start_cluster
        if: inputs.deploy_immediately
        env:
          EG_TOPIC: "/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/rg-ccw-eventgrid/providers/Microsoft.EventGrid/topics/evgt-ccw-eg-cyclecloud"
          CLUSTER_NAME: ${{ inputs.cluster_name }}
          RG_NAME: ${{ steps.rg_name.outputs.resource_group }}
          VM_NAME: "ccw-cyclecloud-vm"
        run: |
          set +x
          set -euo pipefail

          echo "üìù Injecting EventGrid topic into CycleCloud Application.Setting..."
          echo "üîó Topic: ${EG_TOPIC}"

          # Create the application setting file on the CycleCloud VM
          read -r -d '' SCRIPT_CONTENT <<'EOFSCRIPT' || true
          cat > /tmp/eventgrid_topic.txt <<EOF
          AdType = "Application.Setting"
          Description = "Sends CycleCloud events to EventGrid"
          Name = "cyclecloud.eventgrid_topic"
          Value = "${EG_TOPIC}"
          EOF
          chown cycle_server:cycle_server /tmp/eventgrid_topic.txt
          chmod 664 /tmp/eventgrid_topic.txt
          mv /tmp/eventgrid_topic.txt /opt/cycle_server/config/data/eventgrid_topic.txt
          EOFSCRIPT

          # Substitute the actual EG_TOPIC value into the script
          SCRIPT_CONTENT="${SCRIPT_CONTENT//\$\{EG_TOPIC\}/$EG_TOPIC}"

          echo "üìù Script content is:"
          echo "$SCRIPT_CONTENT"
          echo "Executing script on VM to inject EventGrid topic..."
          az vm run-command invoke \
            --resource-group "$RG_NAME" \
            --name "$VM_NAME" \
            --command-id RunShellScript \
            --scripts "$SCRIPT_CONTENT" \
            --query "value[0].message" \
            --output tsv

          # Start the cluster after injecting the EventGrid topic
          echo "üöÄ Starting Slurm cluster '${CLUSTER_NAME}'..."
          az vm run-command invoke \
            --resource-group "$RG_NAME" \
            --name "$VM_NAME" \
            --command-id RunShellScript \
            --scripts "/usr/local/bin/cyclecloud start_cluster \"${CLUSTER_NAME}\"" \
            --query "value[0].message" \
            --output tsv

          # Capture cluster start time in ISO 8601 format
          CLUSTER_START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          echo "‚è±Ô∏è Cluster start time: ${CLUSTER_START_TIME}"
          echo "cluster_start_time=${CLUSTER_START_TIME}" >> "$GITHUB_OUTPUT"

          echo "‚úÖ EventGrid topic injected successfully"

      - name: Re-authenticate with Azure (refresh token)
        if: inputs.deploy_immediately
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Check nodes ready in Log Analytics
        if: inputs.deploy_immediately
        timeout-minutes: 30
        env:
          LOG_ANALYTICS_RG: "rg-ccw-eventgrid"
          LOG_ANALYTICS_WORKSPACE_NAME: "law-ccw-eg"
          NODES_TO_CHECK: '["login-1", "scheduler"]'
          CLUSTER_START_TIME: ${{ steps.start_cluster.outputs.cluster_start_time }}
        run: |
          set -euo pipefail

          echo "üîç Checking if nodes are ready in Log Analytics..."
          echo "üìã Nodes to check: ${NODES_TO_CHECK}"

          # Dynamically retrieve the Log Analytics Workspace ID
          echo "üîß Retrieving Log Analytics Workspace ID..."
          LOG_ANALYTICS_WORKSPACE_ID=$(az monitor log-analytics workspace show \
            --resource-group "${LOG_ANALYTICS_RG}" \
            --workspace-name "${LOG_ANALYTICS_WORKSPACE_NAME}" \
            --query "customerId" \
            --output tsv)

          if [ -z "${LOG_ANALYTICS_WORKSPACE_ID}" ]; then
            echo "‚ùå ERROR: Failed to retrieve Log Analytics Workspace ID"
            echo "::error::Could not get workspace ID for ${LOG_ANALYTICS_WORKSPACE_NAME} in ${LOG_ANALYTICS_RG}"
            exit 1
          fi
          echo "‚úÖ Retrieved Workspace ID: ${LOG_ANALYTICS_WORKSPACE_ID}"

          # Use cluster start time from previous step
          START_TIME="${CLUSTER_START_TIME}"
          echo "‚è±Ô∏è Checking for events since cluster start: ${START_TIME}"

          # KQL query to check node readiness
          KQL_QUERY="let nodesToCheck = dynamic(${NODES_TO_CHECK});
          let startTime = datetime(${START_TIME});
          CycleCloudEvents_CL
          | where TimeGenerated > startTime
          | where NodeName in (nodesToCheck)
          | where EventType == \"Microsoft.CycleCloud.NodeCreated\"
          | summarize arg_max(TimeGenerated, Status, VmSku, Message) by ClusterName, NodeName
          | extend IsReady = (Status == \"Succeeded\")
          | project ClusterName, NodeName, VmSku, LastEvent = TimeGenerated, Status, IsReady, Message
          | order by NodeName asc"

          TIMEOUT_MINUTES=30
          CHECK_INTERVAL=60  # Check every 60 seconds
          MAX_ATTEMPTS=$((TIMEOUT_MINUTES * 60 / CHECK_INTERVAL))
          REQUIRED_NODES=$(echo "${NODES_TO_CHECK}" | jq 'length')

          echo "üîß DEBUG: Required nodes count: ${REQUIRED_NODES}"
          echo "üîß DEBUG: KQL Query:"
          echo "----------------------------------------"
          echo "${KQL_QUERY}"
          echo "----------------------------------------"

          NODES_READY=false

          # Diagnostic: Check what events exist in the table
          echo "üîß DIAGNOSTIC: Checking what events exist in CycleCloudEvents_CL..."
          DIAG_QUERY="CycleCloudEvents_CL
          | where TimeGenerated > ago(1h)
          | summarize count() by EventType, NodeName
          | order by count_ desc
          | take 20"

          DIAG_RESULT=$(az monitor log-analytics query \
            --workspace "${LOG_ANALYTICS_WORKSPACE_ID}" \
            --analytics-query "${DIAG_QUERY}" \
            --output json 2>&1) || true
          echo "üîß DIAGNOSTIC: Events in table:"
          echo "${DIAG_RESULT}" | jq '.' 2>/dev/null || echo "${DIAG_RESULT}"
          echo "----------------------------------------"

          for attempt in $(seq 1 "$MAX_ATTEMPTS"); do
            echo "üîÑ Attempt ${attempt}/${MAX_ATTEMPTS}: Querying Log Analytics..."
            echo "üîß DEBUG: Workspace ID: ${LOG_ANALYTICS_WORKSPACE_ID}"

            # Run the query against Log Analytics - capture both stdout and stderr
            echo "üîß DEBUG: Running az monitor log-analytics query..."
            QUERY_OUTPUT=$(az monitor log-analytics query \
              --workspace "${LOG_ANALYTICS_WORKSPACE_ID}" \
              --analytics-query "${KQL_QUERY}" \
              --output json 2>&1) || true
            
            QUERY_EXIT_CODE=$?
            echo "üîß DEBUG: az command exit code: ${QUERY_EXIT_CODE}"
            echo "üîß DEBUG: Raw query output (first 2000 chars):"
            echo "${QUERY_OUTPUT}" | head -c 2000
            echo ""
            
            # Check if output is valid JSON
            if echo "${QUERY_OUTPUT}" | jq empty 2>/dev/null; then
              echo "üîß DEBUG: Output is valid JSON"
              RESULT="${QUERY_OUTPUT}"
              
              # Check the structure of the result
              echo "üîß DEBUG: JSON type: $(echo "${RESULT}" | jq 'type')"
              echo "üîß DEBUG: JSON length: $(echo "${RESULT}" | jq 'length')"
              
              # If it's an object with 'tables' key (Log Analytics API v2 format)
              if echo "${RESULT}" | jq -e '.tables' >/dev/null 2>&1; then
                echo "üîß DEBUG: Detected tables format, extracting rows..."
                RESULT=$(echo "${QUERY_OUTPUT}" | jq '[.tables[0] | .columns as $cols | .rows[] | [[$cols[].name], .] | transpose | map({(.[0]): .[1]}) | add]')
                echo "üîß DEBUG: Extracted result: ${RESULT}"
              fi
            else
              echo "‚ö†Ô∏è DEBUG: Output is NOT valid JSON"
              echo "üîß DEBUG: Checking for error messages..."
              if echo "${QUERY_OUTPUT}" | grep -qi "error\|failed\|unauthorized"; then
                echo "‚ùå DEBUG: Error detected in output"
              fi
              RESULT="[]"
            fi

            echo "üìä Query result: ${RESULT}"

            # Count nodes where IsReady is true (Log Analytics returns boolean as string "True"/"False")
            READY_COUNT=$(echo "$RESULT" | jq '[.[] | select(.IsReady == true or .IsReady == "True")] | length' 2>/dev/null || echo "0")

            echo "üìà Ready nodes: ${READY_COUNT}/${REQUIRED_NODES}"

            if [ "$READY_COUNT" -ge "$REQUIRED_NODES" ]; then
              echo "‚úÖ All required nodes are ready!"
              echo "$RESULT" | jq -r '.[] | "  - \(.NodeName): \(.Status) (\(.VmSku))"'
              NODES_READY=true
              break
            else
              echo "‚è≥ Nodes not ready yet. Found ${READY_COUNT}/${REQUIRED_NODES} ready nodes."
              # Show current status of found nodes
              if [ "$RESULT" != "[]" ]; then
                echo "$RESULT" | jq -r '.[] | "  - \(.NodeName): \(.Status)"' 2>/dev/null || true
              fi
            fi

            if [ "$attempt" -lt "$MAX_ATTEMPTS" ]; then
              echo "üí§ Waiting ${CHECK_INTERVAL} seconds before next check..."
              sleep "$CHECK_INTERVAL"
            fi
          done

          if [ "$NODES_READY" = false ]; then
            echo "‚ùå FAILURE: Required nodes not ready after ${TIMEOUT_MINUTES} minutes"
            echo "::error::Node readiness check failed: login-1 and scheduler not ready in Log Analytics"
            exit 1
          else
            echo "üéâ SUCCESS: All required nodes (login-1, scheduler) are ready"
            echo "::notice::Node readiness check passed"
          fi

      - name: Query node startup time summary
        if: inputs.deploy_immediately
        env:
          LOG_ANALYTICS_RG: "rg-ccw-eventgrid"
          LOG_ANALYTICS_WORKSPACE_NAME: "law-ccw-eg"
          CLUSTER_START_TIME: ${{ steps.start_cluster.outputs.cluster_start_time }}
        run: |
          set -euo pipefail

          echo "üìä Querying node startup time summary..."
          echo "‚è±Ô∏è Using cluster start time: ${CLUSTER_START_TIME}"

          # Retrieve the Log Analytics Workspace ID
          LOG_ANALYTICS_WORKSPACE_ID=$(az monitor log-analytics workspace show \
            --resource-group "${LOG_ANALYTICS_RG}" \
            --workspace-name "${LOG_ANALYTICS_WORKSPACE_NAME}" \
            --query "customerId" \
            --output tsv)

          if [ -z "${LOG_ANALYTICS_WORKSPACE_ID}" ]; then
            echo "‚ö†Ô∏è WARNING: Failed to retrieve Log Analytics Workspace ID"
            echo "Skipping node startup time summary..."
            exit 0
          fi

          # KQL query to get node startup times
          KQL_QUERY="let startTime = datetime(${CLUSTER_START_TIME});
          CycleCloudEvents_CL
          | where TimeGenerated > startTime
          | where EventType == \"Microsoft.CycleCloud.NodeCreated\"
          | where Status == \"Succeeded\"
          | extend VMCreateTime = Timing.CreateVM, ConfigureTime = Timing.Configure
          | project TimeGenerated, ClusterName, NodeName, VmSku, Status, VMCreateTime, ConfigureTime
          | order by TimeGenerated desc"

          echo "üîß Executing KQL query..."
          QUERY_OUTPUT=$(az monitor log-analytics query \
            --workspace "${LOG_ANALYTICS_WORKSPACE_ID}" \
            --analytics-query "${KQL_QUERY}" \
            --output json 2>&1) || true

          # Check if output is valid JSON
          if ! echo "${QUERY_OUTPUT}" | jq empty 2>/dev/null; then
            echo "‚ö†Ô∏è WARNING: Query output is not valid JSON"
            echo "Skipping node startup time summary..."
            exit 0
          fi

          # Extract results - handle Log Analytics API v2 format
          if echo "${QUERY_OUTPUT}" | jq -e '.tables' >/dev/null 2>&1; then
            RESULT=$(echo "${QUERY_OUTPUT}" | jq '[.tables[0] | .columns as $cols | .rows[] | [[$cols[].name], .] | transpose | map({(.[0]): .[1]}) | add]')
          else
            RESULT="${QUERY_OUTPUT}"
          fi

          RESULT_COUNT=$(echo "$RESULT" | jq 'length')

          if [ "$RESULT_COUNT" -eq 0 ]; then
            echo "‚ÑπÔ∏è No node startup events found since cluster start (${CLUSTER_START_TIME})"
            echo "## Node Startup Times" >> "$GITHUB_STEP_SUMMARY"
            echo "‚ÑπÔ∏è No node startup events found since cluster start (${CLUSTER_START_TIME})" >> "$GITHUB_STEP_SUMMARY"
            exit 0
          fi

          echo "‚úÖ Found ${RESULT_COUNT} node startup events"

          # Generate summary table
          {
            echo "## Node Startup Times"
            echo ""
            echo "| Node Name | VM SKU | VM Create Time | Configure Time | Timestamp |"
            echo "|-----------|--------|----------------|----------------|-----------|"
            echo "$RESULT" | jq -r '.[] | "| \(.NodeName) | \(.VmSku) | \(.VMCreateTime) | \(.ConfigureTime) | \(.TimeGenerated) |"'
            echo ""
          } >> "$GITHUB_STEP_SUMMARY"

          echo "üìã Node startup time summary added to job summary"

      - name: Check CycleCloud VM cloud-init logs
        if: failure() && inputs.deploy_immediately
        run: |
          set -euo pipefail
          RG_NAME="${{ steps.rg_name.outputs.resource_group }}"

          echo "üîç Checking cloud-init logs on CycleCloud VM"
          az vm run-command invoke \
            --resource-group "$RG_NAME" \
            --name "ccw-cyclecloud-vm" \
            --command-id RunShellScript \
            --scripts "tail -n 200 /var/log/cloud-init-output.log" \
            --query "value[0].message" \
            --output tsv

      - name: Display deployment summary
        if: always()
        run: |
          set -euo pipefail
          {
            echo "## Deployment Summary"
            echo "- **Workspace Reference**: ${{ inputs.workspace_ref }}"
            echo "- **Resource Group**: ${{ steps.rg_name.outputs.resource_group }}"
            echo "- **Location**: ${{ inputs.location }}"
            echo "- **Data Filesystem (Lustre)**: ${{ inputs.data_filesystem }}"
            echo "- **Deploy Immediately**: ${{ inputs.deploy_immediately }}"
          } >> "$GITHUB_STEP_SUMMARY"

          if [ -f "infrastructure_references/azure_cyclecloud_workspace_for_slurm/scripts/output.json" ]; then
            echo "‚úÖ Parameters file generated successfully" >> "$GITHUB_STEP_SUMMARY"
            echo "=================================="
            jq -c . infrastructure_references/azure_cyclecloud_workspace_for_slurm/scripts/output.json >> "$GITHUB_STEP_SUMMARY"
            echo "=================================="
          fi

      - name: List resources before cleanup
        if: always() && inputs.deploy_immediately
        run: |
          set -euo pipefail
          RG_NAME="${{ steps.rg_name.outputs.resource_group }}"
          echo "üìã Listing all resources in resource group: ${RG_NAME}"

          if az group exists --name "$RG_NAME" --output tsv 2>/dev/null | grep -q "true"; then
            echo "Resource group exists, listing resources..."
            RESOURCES=$(az resource list --resource-group "$RG_NAME" --query "[].{Name:name, Type:type}" --output table 2>/dev/null || echo "")
            
            if [ -n "$RESOURCES" ]; then
              {
                echo "## Resources in Resource Group '${RG_NAME}'"
                echo '```'
                echo "$RESOURCES"
                echo '```'
              } >> "$GITHUB_STEP_SUMMARY"
              echo "Found resources:"
              echo "$RESOURCES"
            else
              echo "No resources found in resource group"
              echo "‚ÑπÔ∏è No resources found in resource group '${RG_NAME}'" >> "$GITHUB_STEP_SUMMARY"
            fi
          else
            echo "Resource group '${RG_NAME}' does not exist"
            echo "‚ÑπÔ∏è Resource group '${RG_NAME}' does not exist" >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Cleanup resource group after deployment
        if: always() && inputs.deploy_immediately
        run: |
          set -euo pipefail
          echo "Cleaning up resource group: ${{ steps.rg_name.outputs.resource_group }}"
          if az group exists --name "${{ steps.rg_name.outputs.resource_group }}" --output tsv 2>/dev/null | grep -q "true"; then
            echo "Resource group exists, deleting..."
            az group delete --name "${{ steps.rg_name.outputs.resource_group }}" --yes --no-wait
            echo "‚úÖ Resource group deletion initiated" >> "$GITHUB_STEP_SUMMARY"
          else
            echo "Resource group does not exist, nothing to clean up"
          fi
